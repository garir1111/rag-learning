{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4章 LangChainの基礎\n",
        "\n",
        "これ一生Jupyterでやる気か。。。？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Python 3.11.13 | NumPy 1.26.4 | Pandas 2.3.1 | Polars 1.31.0 | Matplotlib 3.10.3 | Seaborn 0.13.2 | Scikit-learn 1.7.1\n"
          ]
        }
      ],
      "source": [
        "import sys, numpy, pandas, polars, matplotlib, seaborn, sklearn\n",
        "print(f\"✅ Python {sys.version.split()[0]} | NumPy {numpy.__version__} | Pandas {pandas.__version__} | Polars {polars.__version__} | Matplotlib {matplotlib.__version__} | Seaborn {seaborn.__version__} | Scikit-learn {sklearn.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LangChainとは\n",
        "\n",
        "LLMアプリケーション開発のフレームワーク。\n",
        "そのほかにもLlamaIndex, Semantic Kernelが有名であるが、LangChainは機能が幅広い。\n",
        "\n",
        "## 全体像\n",
        "\n",
        "コア的なところと、エコシステム的なところに分かれる。\n",
        "\n",
        "## langchain-core\n",
        "\n",
        "中核的なところ。\n",
        "基本的にはこいつをインストールして、必要なものだけをインストールする。\n",
        "\n",
        "\n",
        "```bash\n",
        "uv add langchain-core==0.3.0 langchain-openai==0.2.0\n",
        "```\n",
        "\n",
        "## langsmith\n",
        "\n",
        "langsmithはLangChainの動作トレースを収集することが出来る。\n",
        "以下のようにセットアップできる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
        "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
        "os.environ['LANGCHAIN_PROJECT'] = \"agent-book\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LangChain - LLM\n",
        "\n",
        "LangChainのモジュールであるLLMは、単一テキストの入力に単一テキストを返す言語モデルを扱うためのコンポーネントである。\n",
        "\n",
        "completion chat(4o)ではなく、completions(3.5-turbo)を使う場合などはこれを使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "PydanticUserError",
          "evalue": "`OpenAI` is not fully defined; you should define `BaseCache`, then call `OpenAI.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/class-not-fully-defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mPydanticUserError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# これでクラス定義を強制的に再構築してみる\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# OpenAI.model_rebuild()\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# temperatureはAIの遊び幅\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# model = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m model = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-3.5-turbo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m output = model.invoke(\u001b[33m\"\u001b[39m\u001b[33m楽しく自己紹介してください。\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(output)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dev/maki.yoshida/rag_learning/.venv/lib/python3.11/site-packages/langchain_core/load/serializable.py:112\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    111\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dev/maki.yoshida/rag_learning/.venv/lib/python3.11/site-packages/pydantic/_internal/_mock_val_ser.py:100\u001b[39m, in \u001b[36mMockValSer.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# raise an AttributeError if `item` doesn't exist\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._val_or_ser, item)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\u001b[38;5;28mself\u001b[39m._error_message, code=\u001b[38;5;28mself\u001b[39m._code)\n",
            "\u001b[31mPydanticUserError\u001b[39m: `OpenAI` is not fully defined; you should define `BaseCache`, then call `OpenAI.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/class-not-fully-defined"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "# これでクラス定義を強制的に再構築してみる\n",
        "# OpenAI.model_rebuild()\n",
        "\n",
        "# temperatureはAIの遊び幅\n",
        "# model = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
        "model = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "output = model.invoke(\"楽しく自己紹介してください。\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "☝️多分これ動かない"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "PydanticUserError",
          "evalue": "`ChatOpenAI` is not fully defined; you should define `BaseCache`, then call `ChatOpenAI.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/class-not-fully-defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mPydanticUserError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# クラス定義を強制的に再構築する\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# ChatOpenAI.model_rebuild()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m messages = [\n\u001b[32m     10\u001b[39m     SystemMessage(content=\u001b[33m\"\u001b[39m\u001b[33mYou are a helpful assistant\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     11\u001b[39m     HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mこんにちは、私はジョンといいます。\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     12\u001b[39m     AIMessage(content=\u001b[33m\"\u001b[39m\u001b[33mこんにちは、ジョンさん！本日はどのようにお手伝いできますか？\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     13\u001b[39m     HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33m私の名前がわかりますか？\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     14\u001b[39m ]\n\u001b[32m     16\u001b[39m ai_message = model.invoke(messages)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dev/maki.yoshida/rag_learning/.venv/lib/python3.11/site-packages/langchain_core/load/serializable.py:112\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    111\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dev/maki.yoshida/rag_learning/.venv/lib/python3.11/site-packages/pydantic/_internal/_mock_val_ser.py:100\u001b[39m, in \u001b[36mMockValSer.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# raise an AttributeError if `item` doesn't exist\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._val_or_ser, item)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\u001b[38;5;28mself\u001b[39m._error_message, code=\u001b[38;5;28mself\u001b[39m._code)\n",
            "\u001b[31mPydanticUserError\u001b[39m: `ChatOpenAI` is not fully defined; you should define `BaseCache`, then call `ChatOpenAI.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/class-not-fully-defined"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant\"),\n",
        "    HumanMessage(content=\"こんにちは、私はジョンといいます。\"),\n",
        "    AIMessage(content=\"こんにちは、ジョンさん！本日はどのようにお手伝いできますか？\"),\n",
        "    HumanMessage(content=\"私の名前がわかりますか？\"),\n",
        "]\n",
        "\n",
        "ai_message = model.invoke(messages)\n",
        "print(ai_message)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rag_learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
